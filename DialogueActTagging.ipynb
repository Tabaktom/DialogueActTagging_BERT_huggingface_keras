{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_ZORURKg-fp"
   },
   "source": [
    "# Lab 11: Dialogue Act Tagging\n",
    "\n",
    "Dialogue act (DA) tagging is an important step in the process of developing dialog systems. DA tagging is a problem usually solved by supervised machine learning approaches that all require large amounts of hand labeled data. A wide range of techniques have been investigated for DA tagging. In this lab, we explore two approaches to DA classification. We are using the Switchboard Dialog Act Corpus for training.\n",
    "Corpus can be downloaded from http://compprag.christopherpotts.net/swda.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ziKyA9R4gyw9"
   },
   "source": [
    "The downloaded dataset should be kept in a data folder in the same directory as this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jmTpKt_uefe5",
    "outputId": "cb0a6cbd-50a3-4613-986f-5172ffcf875b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.15.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
      "\u001b[K     |████████████████████████████████| 411.0MB 34kB/s \n",
      "\u001b[?25hCollecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.10.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 65.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.28.1)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 55.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.18.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.34.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2) (46.1.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=716e98de987dddbb02704c5c316fb46be7a0f5bce26127bb3a051bc4d0a7e847\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc2 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc2 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc2 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
      "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
      "  Found existing installation: tensorboard 2.2.0\n",
      "    Uninstalling tensorboard-2.2.0:\n",
      "      Successfully uninstalled tensorboard-2.2.0\n",
      "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n",
      "--2020-04-16 07:18:34--  http://compprag.christopherpotts.net/code-data/swda.zip\n",
      "Resolving compprag.christopherpotts.net (compprag.christopherpotts.net)... 64.90.36.20\n",
      "Connecting to compprag.christopherpotts.net (compprag.christopherpotts.net)|64.90.36.20|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14040987 (13M) [application/zip]\n",
      "Saving to: ‘swda.zip’\n",
      "\n",
      "swda.zip            100%[===================>]  13.39M  9.32MB/s    in 1.4s    \n",
      "\n",
      "2020-04-16 07:18:36 (9.32 MB/s) - ‘swda.zip’ saved [14040987/14040987]\n",
      "\n",
      "Archive:  swda.zip\n",
      "   creating: swda/\n",
      "  inflating: swda/.DS_Store          \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/swda/\n",
      "  inflating: __MACOSX/swda/._.DS_Store  \n",
      "   creating: swda/sw00utt/\n",
      "  inflating: swda/sw00utt/sw_0001_4325.utt.csv  \n",
      "   creating: __MACOSX/swda/sw00utt/\n",
      "  inflating: __MACOSX/swda/sw00utt/._sw_0001_4325.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0002_4330.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0003_4103.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0004_4327.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0005_4646.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0006_4108.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0007_4171.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0008_4321.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0009_4329.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0010_4356.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0011_4358.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0012_4360.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0013_4617.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0014_4619.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0015_4877.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0016_3389.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0017_4036.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0018_4082.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0019_4104.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0020_4109.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0021_4168.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0022_4320.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0023_4341.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0024_4688.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0025_2451.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0026_3902.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0027_4096.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0028_4133.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0029_4152.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0030_4166.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0031_4319.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0032_4333.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0033_4336.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0034_4345.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0035_4372.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0036_4379.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0037_4382.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0038_4611.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0039_4628.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0040_2095.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0041_4048.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0042_4060.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0043_4148.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0044_4177.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0045_4312.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0046_4316.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0047_4339.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0048_4340.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0049_4353.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0050_4362.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0051_4364.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0052_4378.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0053_2184.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0054_2789.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0055_3156.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0056_3351.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0057_3506.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0058_3707.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0059_4028.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0060_4038.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0061_4151.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0062_4158.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0063_4334.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0064_4346.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0065_4349.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0066_2593.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0067_2945.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0068_3075.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0069_3144.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0070_3435.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0071_3658.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0072_3876.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0073_4049.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0074_4127.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0075_4129.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0076_4153.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0077_4155.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0078_4181.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0079_4318.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0080_4366.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0081_4380.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0082_4626.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0083_4830.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0084_2109.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0085_2395.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0086_2546.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0087_2775.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0088_3073.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0089_3086.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0090_3133.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0091_3135.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0092_3154.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0093_3227.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0094_3315.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0095_3445.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0096_3580.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0097_3798.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0098_3830.utt.csv  \n",
      "  inflating: swda/sw00utt/sw_0099_3917.utt.csv  \n",
      "   creating: swda/sw01utt/\n",
      "  inflating: swda/sw01utt/sw_0100_3925.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0101_4019.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0102_4033.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0103_4074.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0104_4101.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0105_4123.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0106_4137.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0107_4150.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0108_4175.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0109_4342.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0110_4880.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0111_2018.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0112_2061.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0113_2093.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0114_2107.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0115_2370.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0116_2406.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0117_2837.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0118_3080.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0119_3083.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0120_3113.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0121_3140.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0122_3161.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0123_3186.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0124_3201.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0125_3306.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0126_3349.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0127_3411.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0128_3441.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0129_3476.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0130_3514.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0131_3561.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0132_3682.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0133_3796.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0134_3887.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0135_4090.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0136_4099.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0137_4370.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0138_4890.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0139_4908.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0140_4928.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0141_2060.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0142_2145.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0143_2290.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0144_2399.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0145_2429.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0146_2477.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0147_2539.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0148_2604.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0149_2611.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0150_2628.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0151_2772.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0152_3108.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0153_3138.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0154_3142.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0155_3219.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0156_3252.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0157_3304.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0158_3327.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0159_3369.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0160_3467.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0161_3781.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0162_3801.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0163_3821.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0164_3862.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0165_4079.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0166_4519.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0167_4736.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0168_4765.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0169_4831.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0170_4868.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0171_2028.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0172_2305.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0173_2548.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0174_2708.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0175_2729.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0176_2749.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0177_2759.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0178_3038.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0179_3120.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0180_3134.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0181_3146.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0182_3152.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0183_3169.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0184_3171.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0185_3174.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0186_3188.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0187_3242.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0188_3251.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0189_3266.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0190_3324.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0191_3427.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0192_3495.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0193_3508.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0194_3595.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0195_3763.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0196_3838.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0197_3883.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0198_3962.utt.csv  \n",
      "  inflating: swda/sw01utt/sw_0199_4004.utt.csv  \n",
      "   creating: swda/sw02utt/\n",
      "  inflating: swda/sw02utt/sw_0200_4159.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0201_4311.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0202_4376.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0203_4603.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0204_4698.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0205_4725.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0206_4859.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0207_2039.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0208_2094.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0209_2102.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0210_2113.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0211_2163.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0212_2275.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0213_2285.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0214_2302.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0215_2314.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0216_2336.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0217_2421.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0218_2465.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0219_2472.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0220_2549.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0221_2566.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0222_2676.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0223_2703.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0224_2818.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0225_2877.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0226_3081.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0227_3093.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0228_3115.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0229_3130.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0230_3148.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0231_3150.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0232_3159.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0233_3182.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0234_3195.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0235_3232.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0236_3235.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0237_3279.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0238_3364.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0239_3367.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0240_3387.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0241_3403.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0242_3503.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0243_3513.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0244_3526.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0245_3565.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0246_3615.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0247_3660.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0248_3697.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0249_3728.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0250_3850.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0251_4026.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0252_4071.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0253_4072.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0254_4138.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0255_4548.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0256_4728.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0257_4876.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0258_2008.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0259_2020.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0260_2073.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0261_2120.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0262_2137.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0263_2226.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0264_2252.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0265_2264.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0266_2299.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0267_2362.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0268_2366.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0269_2382.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0270_2397.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0271_2435.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0272_2479.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0273_2485.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0274_2527.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0275_2540.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0276_2565.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0277_2598.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0278_2599.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0279_2602.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0280_2648.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0281_2657.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0282_2672.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0283_2710.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0284_2743.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0285_2756.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0286_2785.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0287_2819.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0288_2828.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0289_2832.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0290_2851.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0291_2876.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0292_3023.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0293_3069.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0294_3088.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0295_3200.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0296_3202.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0297_3223.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0298_3245.utt.csv  \n",
      "  inflating: swda/sw02utt/sw_0299_3254.utt.csv  \n",
      "   creating: swda/sw03utt/\n",
      "  inflating: swda/sw03utt/sw_0300_3268.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0301_3269.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0302_3309.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0303_3313.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0304_3338.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0305_3343.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0306_3345.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0307_3375.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0308_3646.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0309_3663.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0310_3699.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0311_3776.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0312_3784.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0313_3825.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0314_3983.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0315_3993.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0316_4051.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0317_4064.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0318_4565.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0319_4642.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0320_4720.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0321_4902.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0322_4936.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0323_2022.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0324_2154.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0325_2171.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0326_2249.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0327_2253.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0328_2349.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0329_2372.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0330_2466.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0331_2488.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0332_2571.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0333_2584.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0334_2587.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0335_2589.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0336_2603.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0337_2608.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0338_2641.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0339_2669.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0340_2678.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0341_2932.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0342_2956.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0343_2965.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0344_3020.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0345_3021.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0346_3047.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0347_3052.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0348_3062.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0349_3082.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0350_3103.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0351_3207.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0352_3236.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0353_3239.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0354_3286.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0355_3300.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0356_3303.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0357_3360.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0358_3362.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0359_3393.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0360_3397.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0361_3398.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0362_3447.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0363_3487.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0364_3491.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0365_3515.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0366_3517.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0367_3524.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0368_3541.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0369_3584.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0370_3636.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0371_3688.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0372_3725.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0373_4013.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0374_4032.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0375_4050.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0376_4077.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0377_4130.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0378_4154.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0379_4483.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0380_4572.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0381_4784.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0382_4785.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0383_4812.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0384_2005.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0385_2012.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0386_2035.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0387_2067.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0388_2078.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0389_2157.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0390_2241.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0391_2259.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0392_2405.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0393_2407.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0394_2427.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0395_2442.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0396_2490.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0397_2492.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0398_2504.utt.csv  \n",
      "  inflating: swda/sw03utt/sw_0399_2526.utt.csv  \n",
      "   creating: swda/sw04utt/\n",
      "  inflating: swda/sw04utt/sw_0400_2558.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0401_2568.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0402_2634.utt.csv  \n",
      "   creating: __MACOSX/swda/sw04utt/\n",
      "  inflating: __MACOSX/swda/sw04utt/._sw_0402_2634.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0403_2650.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0404_2667.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0405_2717.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0406_2784.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0407_2826.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0408_2860.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0409_2866.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0410_2970.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0411_2998.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0412_3015.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0413_3041.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0414_3067.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0415_3168.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0416_3205.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0417_3237.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0418_3275.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0419_3284.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0420_3288.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0421_3311.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0422_3320.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0423_3325.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0424_3328.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0425_3382.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0426_3409.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0427_3509.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0428_3550.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0429_3607.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0430_3633.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0431_3655.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0432_3720.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0433_3727.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0434_3809.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0435_4008.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0436_4055.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0437_4092.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0438_4113.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0439_4314.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0440_4347.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0441_4608.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0442_4649.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0443_4679.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0444_4682.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0445_4697.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0446_4792.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0447_4801.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0448_4826.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0449_4858.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0450_4886.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0451_2062.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0452_2111.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0453_2139.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0454_2231.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0455_2247.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0456_2266.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0457_2304.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0458_2316.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0459_2330.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0460_2331.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0461_2436.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0462_2439.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0463_2469.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0464_2510.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0465_2525.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0466_2547.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0467_2554.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0468_2559.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0469_2615.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0470_2627.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0471_2640.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0472_2653.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0473_2658.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0474_2691.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0475_2761.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0476_2790.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0477_2868.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0478_2896.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0479_2910.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0480_3040.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0481_3045.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0482_3068.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0483_3070.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0484_3085.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0485_3099.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0486_3173.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0487_3206.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0488_3215.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0489_3238.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0490_3246.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0491_3256.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0492_3259.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0493_3296.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0494_3331.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0495_3334.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0496_3344.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0497_3354.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0498_3417.utt.csv  \n",
      "  inflating: swda/sw04utt/sw_0499_3420.utt.csv  \n",
      "   creating: swda/sw05utt/\n",
      "  inflating: swda/sw05utt/sw_0500_3425.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0501_3450.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0502_3525.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0503_3539.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0504_3549.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0505_3569.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0506_3576.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0507_3606.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0508_3628.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0509_3639.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0510_3680.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0511_3746.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0512_3811.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0513_3988.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0514_4174.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0515_4184.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0516_4618.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0517_4633.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0518_4691.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0519_4733.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0520_2010.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0521_2041.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0522_2072.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0523_2092.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0524_2124.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0525_2130.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0526_2160.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0527_2177.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0528_2260.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0529_2324.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0530_2334.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0531_2365.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0532_2455.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0533_2486.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0534_2499.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0535_2501.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0536_2502.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0537_2521.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0538_2545.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0539_2609.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0540_2619.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0541_2719.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0542_2782.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0543_2792.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0544_2800.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0545_2840.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0546_2913.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0547_3051.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0548_3074.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0549_3111.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0550_3124.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0551_3155.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0552_3187.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0553_3229.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0554_3260.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0555_3294.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0556_3317.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0557_3333.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0558_3342.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0559_3365.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0560_3377.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0561_3406.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0562_3443.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0563_3458.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0564_3497.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0565_3523.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0566_3551.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0567_3574.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0568_3586.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0569_3638.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0570_3691.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0571_3750.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0572_3768.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0573_4022.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0574_4023.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0575_4114.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0576_4363.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0577_4659.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0578_4796.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0579_4834.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0580_2015.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0581_2032.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0582_2051.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0583_2053.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0584_2220.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0585_2279.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0586_2295.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0587_2383.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0588_2423.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0589_2433.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0590_2445.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0591_2460.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0592_2533.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0593_2597.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0594_2617.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0595_2645.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0596_2734.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0597_2835.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0598_2858.utt.csv  \n",
      "  inflating: swda/sw05utt/sw_0599_2870.utt.csv  \n",
      "   creating: swda/sw06utt/\n",
      "  inflating: swda/sw06utt/sw_0600_2883.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0601_2893.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0602_2938.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0603_2962.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0604_2969.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0605_2989.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0606_3011.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0607_3012.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0608_3030.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0609_3049.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0610_3056.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0611_3072.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0612_3090.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0613_3096.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0614_3097.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0615_3131.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0616_3283.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0617_3353.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0618_3368.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0619_3399.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0620_3408.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0621_3449.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0622_3473.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0623_3537.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0624_3557.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0625_3573.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0626_3596.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0627_3651.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0628_3773.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0629_4056.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0630_4080.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0631_4149.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0632_4707.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0633_2024.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0634_2027.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0635_2065.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0636_2079.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0637_2104.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0638_2105.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0639_2187.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0640_2309.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0641_2313.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0642_2450.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0643_2452.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0644_2476.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0645_2537.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0646_2575.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0647_2579.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0648_2616.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0649_2620.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0650_2642.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0651_2766.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0652_2797.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0653_2806.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0654_2847.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0655_2849.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0656_2887.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0657_2900.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0658_2992.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0659_3143.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0660_3190.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0661_3194.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0662_3196.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0663_3225.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0664_3330.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0665_3355.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0666_3359.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0667_3372.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0668_3373.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0669_3381.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0670_3386.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0671_3421.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0672_3453.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0673_3504.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0674_3666.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0675_3675.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0676_3804.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0677_3805.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0678_3845.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0679_3898.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0680_3926.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0681_4147.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0682_4660.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0683_4675.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0684_4723.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0685_4726.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0686_4829.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0687_2085.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0688_2181.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0689_2197.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0690_2268.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0691_2283.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0692_2287.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0693_2300.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0694_2380.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0695_2424.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0696_2431.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0697_2514.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0698_2515.utt.csv  \n",
      "  inflating: swda/sw06utt/sw_0699_2519.utt.csv  \n",
      "   creating: swda/sw07utt/\n",
      "  inflating: swda/sw07utt/sw_0700_2586.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0701_2631.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0702_2652.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0703_2661.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0704_2690.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0705_2713.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0706_2751.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0707_2755.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0708_2927.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0709_2952.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0710_2996.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0711_3007.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0712_3029.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0713_3036.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0714_3039.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0715_3092.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0716_3105.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0717_3384.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0718_3543.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0719_3587.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0720_3696.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0721_3777.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0722_3791.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0723_3797.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0724_3802.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0725_3911.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0726_4443.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0727_4605.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0728_4759.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0729_4840.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0730_4905.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0731_4917.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0732_4927.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0733_4940.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0734_2019.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0735_2025.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0736_2071.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0737_2110.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0738_2178.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0739_2180.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0740_2185.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0741_2221.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0742_2235.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0743_2265.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0744_2376.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0745_2387.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0746_2448.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0747_2585.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0748_2663.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0749_2726.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0750_2736.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0751_2793.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0752_2963.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0753_3000.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0754_3003.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0755_3018.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0756_3063.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0757_3071.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0758_3087.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0759_3191.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0760_3291.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0761_3340.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0762_3371.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0763_3402.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0764_3431.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0765_3535.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0766_3556.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0767_3591.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0768_3626.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0769_3659.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0770_3681.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0771_3870.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0772_4752.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0773_4821.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0774_4856.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0775_2006.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0776_2086.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0777_2122.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0778_2248.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0779_2301.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0780_2393.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0781_2482.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0782_2570.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0783_2622.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0784_2630.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0785_2647.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0786_2875.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0787_2926.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0788_2984.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0789_2999.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0790_3002.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0791_3050.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0792_3065.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0793_3095.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0794_3234.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0795_3429.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0796_3464.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0797_3563.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0798_3736.utt.csv  \n",
      "  inflating: swda/sw07utt/sw_0799_3828.utt.csv  \n",
      "   creating: swda/sw08utt/\n",
      "  inflating: swda/sw08utt/sw_0800_3841.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0801_3908.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0802_3971.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0803_4037.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0804_4165.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0805_4758.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0806_4774.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0807_4799.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0808_2038.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0809_2040.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0810_2232.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0811_2278.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0812_2289.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0813_2296.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0814_2308.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0815_2354.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0816_2368.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0817_2379.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0818_2528.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0819_2594.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0820_2638.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0821_2711.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0822_2776.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0823_2827.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0824_2944.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0825_2953.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0826_2981.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0827_3019.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0828_3055.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0829_3228.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0830_3233.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0831_3253.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0832_3265.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0833_3281.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0834_3282.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0835_3319.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0836_3326.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0837_3379.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0838_3405.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0839_3424.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0840_3426.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0841_3530.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0842_3657.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0843_3738.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0844_3743.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0845_3754.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0846_3956.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0847_3985.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0848_4666.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0849_4709.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0850_4721.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0851_4802.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0852_2090.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0853_2125.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0854_2168.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0855_2191.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0856_2342.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0857_2483.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0858_2506.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0859_2534.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0860_2614.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0861_2684.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0862_2707.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0863_2709.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0864_2716.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0865_2741.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0866_2768.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0867_2770.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0868_2788.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0869_2871.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0870_2888.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0871_2930.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0872_3034.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0873_3042.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0874_3059.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0875_3136.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0876_3158.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0877_3166.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0878_3189.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0879_3433.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0880_3439.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0881_3500.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0882_3554.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0883_3597.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0884_3676.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0885_3745.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0886_3760.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0887_3803.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0888_3813.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0889_3815.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0890_3903.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0891_3921.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0892_3979.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0893_4630.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0894_4703.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0895_4788.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0896_4814.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0897_2244.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0898_2303.utt.csv  \n",
      "  inflating: swda/sw08utt/sw_0899_2325.utt.csv  \n",
      "   creating: swda/sw09utt/\n",
      "  inflating: swda/sw09utt/.DS_Store  \n",
      "   creating: __MACOSX/swda/sw09utt/\n",
      "  inflating: __MACOSX/swda/sw09utt/._.DS_Store  \n",
      "  inflating: swda/sw09utt/sw_0900_2339.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0901_2418.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0902_2552.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0903_2576.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0904_2767.utt.csv  \n",
      "  inflating: __MACOSX/swda/sw09utt/._sw_0904_2767.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0905_2780.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0906_2803.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0907_2830.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0908_2844.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0909_2879.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0910_2955.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0911_3121.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0912_3267.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0913_3361.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0914_3448.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0915_3624.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0916_3642.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0917_3694.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0918_3716.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0919_3723.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0920_3747.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0921_3810.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0922_3946.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0923_4615.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0924_4655.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0925_4681.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0926_2149.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0927_2228.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0928_2234.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0929_2344.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0930_2446.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0931_2467.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0932_2610.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0933_2662.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0934_2744.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0935_2774.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0936_2917.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0937_2950.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0938_2983.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0939_2994.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0940_2995.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0941_3014.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0942_3025.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0943_3028.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0944_3064.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0945_3076.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0946_3107.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0947_3118.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0948_3151.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0949_3216.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0950_3221.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0951_3383.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0952_3454.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0953_3457.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0954_3460.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0955_3489.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0956_3521.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0957_3709.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0958_3734.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0959_3735.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0960_3751.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0961_3770.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0962_3847.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0963_4716.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0964_2237.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0965_2263.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0966_2323.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0967_2340.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0968_2413.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0969_2578.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0970_2773.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0971_2839.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0972_2862.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0973_2934.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0974_2942.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0975_3009.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0976_3046.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0977_3104.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0978_3167.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0979_3181.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0980_3185.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0981_3204.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0982_3310.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0983_3363.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0984_3414.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0985_3428.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0986_3455.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0987_3518.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0988_3570.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0989_3692.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0990_3703.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0991_3855.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0992_3952.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0993_3965.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0994_4644.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0995_4735.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0996_4745.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0997_2155.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0998_2175.utt.csv  \n",
      "  inflating: swda/sw09utt/sw_0999_2227.utt.csv  \n",
      "   creating: swda/sw10utt/\n",
      "  inflating: swda/sw10utt/sw_1000_2292.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1001_2389.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1002_2426.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1003_2524.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1004_2562.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1005_2693.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1006_2967.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1007_2993.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1008_3016.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1009_3102.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1010_3226.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1011_3352.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1012_3527.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1013_4822.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1014_2101.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1015_2355.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1016_2471.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1017_2543.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1018_2692.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1019_2898.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1020_2935.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1021_2954.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1022_2982.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1023_3231.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1024_3247.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1025_3250.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1026_3280.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1027_3463.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1028_3496.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1029_3774.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1030_2064.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1031_2386.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1032_2557.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1033_2723.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1034_2924.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1035_2957.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1036_2960.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1037_3054.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1038_3061.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1039_3077.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1040_3244.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1041_3290.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1042_4078.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1043_2293.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1044_2457.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1045_2495.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1046_2621.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1047_2754.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1048_2794.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1049_2889.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1050_2968.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1051_3170.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1052_3198.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1053_3203.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1054_3208.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1055_3272.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1056_3276.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1057_3293.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1058_3711.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1059_3764.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1060_3852.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1061_4770.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1062_2190.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1063_2432.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1064_2478.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1065_2675.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1066_2679.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1067_2689.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1068_2834.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1069_2884.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1070_3013.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1071_3162.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1072_3270.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1073_3271.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1074_3647.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1075_3665.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1076_3686.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1077_2205.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1078_2437.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1079_2511.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1080_2812.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1081_2821.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1082_2854.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1083_2959.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1084_2991.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1085_3001.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1086_3057.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1087_3214.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1088_3230.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1089_3567.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1090_2353.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1091_2373.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1092_2623.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1093_3184.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1094_3255.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1095_3257.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1096_3346.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1097_3769.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1098_3788.utt.csv  \n",
      "  inflating: swda/sw10utt/sw_1099_2929.utt.csv  \n",
      "   creating: swda/sw11utt/\n",
      "  inflating: swda/sw11utt/sw_1100_3419.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1101_3693.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1102_2820.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1103_2915.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1104_2921.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1105_3175.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1106_3662.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1107_3332.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1108_3533.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1109_2842.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1110_2874.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1111_2897.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1112_3004.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1113_2909.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1114_2262.utt.csv  \n",
      "  inflating: swda/sw11utt/sw_1115_3451.utt.csv  \n",
      "   creating: swda/sw12utt/\n",
      "  inflating: swda/sw12utt/sw_1200_2121.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1201_2131.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1202_2151.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1203_2229.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1204_2434.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1205_2441.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1206_2461.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1207_2503.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1208_2724.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1209_2836.utt.csv  \n",
      "  inflating: swda/sw12utt/sw_1210_3756.utt.csv  \n",
      "   creating: swda/sw13utt/\n",
      "  inflating: swda/sw13utt/sw_1300_2335.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1301_2347.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1302_2505.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1303_2567.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1304_2632.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1305_2702.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1306_2733.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1307_2752.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1308_2753.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1309_2838.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1310_3035.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1311_3129.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1312_3469.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1313_3520.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1314_3528.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1315_3924.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1316_3936.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1317_3942.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1318_3968.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1319_3994.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1320_4002.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1321_4102.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1322_4157.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1323_4167.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1324_4179.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1325_4384.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1326_4622.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1327_4643.utt.csv  \n",
      "  inflating: swda/sw13utt/sw_1328_4771.utt.csv  \n",
      "  inflating: swda/swda-metadata.csv  \n",
      "  inflating: __MACOSX/swda/._swda-metadata.csv  \n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==1.15.2\n",
    "!wget http://compprag.christopherpotts.net/code-data/swda.zip\n",
    "!unzip swda.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "7744z70or8-G",
    "outputId": "660038fd-7956-4a97-d0ea-358119b1f660"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 962
    },
    "colab_type": "code",
    "id": "w0Uo-ulKoncj",
    "outputId": "5dfbe651-f8e8-4a40-8c36-f8392fe5e048"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-87f962e0e46f>\", line 6, in <module>\n",
      "    boost_ram()\n",
      "  File \"<ipython-input-3-87f962e0e46f>\", line 4, in boost_ram\n",
      "    a.append('1')\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 223, in findsource\n",
      "    pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\n",
      "  File \"/usr/lib/python3.6/re.py\", line 233, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.6/re.py\", line 301, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 566, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 551, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 187, in _compile\n",
      "    _compile(code, av, flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 146, in _compile\n",
      "    _compile(code, p, (flags | add_flags) & ~del_flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 126, in _compile\n",
      "    _compile(code, av[2], flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 79, in _compile\n",
      "    for op, av in pattern:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "def boost_ram():\n",
    "  a = []\n",
    "  while(1):\n",
    "    a.append('1')\n",
    "\n",
    "boost_ram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6E8axaw1hAbM"
   },
   "outputs": [],
   "source": [
    "f = glob.glob(\"swda/sw*/sw*.csv\")\n",
    "frames = []\n",
    "for i in range(0, len(f)):\n",
    "    frames.append(pd.read_csv(f[i]))\n",
    "\n",
    "result = pd.concat(frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b7hKGF7EhM4s",
    "outputId": "1d6f4cb8-6cfc-4c8a-bb4e-5755bd48907b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of converations in the dataset: 223606\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of converations in the dataset:\",len(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ttyB2lQhc7B"
   },
   "source": [
    "The dataset has many different features, we are only using act_tag and text for this training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jUifIdshhD0"
   },
   "outputs": [],
   "source": [
    "reduced_df = result[['act_tag','text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iPmZvysqg2i"
   },
   "source": [
    "Reduce down the number of tags to 43 - converting the combined tags to their generic classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQuHm0jPt_lz"
   },
   "outputs": [],
   "source": [
    "# Imported from \"https://github.com/cgpotts/swda\"\n",
    "# Convert the combination tags to the generic 43 tags\n",
    "\n",
    "import re\n",
    "def damsl_act_tag(input):\n",
    "        \"\"\"\n",
    "        Seeks to duplicate the tag simplification described at the\n",
    "        Coders' Manual: http://www.stanford.edu/~jurafsky/ws97/manual.august1.html\n",
    "        \"\"\"\n",
    "        d_tags = []\n",
    "        tags = re.split(r\"\\s*[,;]\\s*\", input)\n",
    "        for tag in tags:\n",
    "            if tag in ('qy^d', 'qw^d', 'b^m'): pass\n",
    "            elif tag == 'nn^e': tag = 'ng'\n",
    "            elif tag == 'ny^e': tag = 'na'\n",
    "            else: \n",
    "                tag = re.sub(r'(.)\\^.*', r'\\1', tag)\n",
    "                tag = re.sub(r'[\\(\\)@*]', '', tag)            \n",
    "                if tag in ('qr', 'qy'):                         tag = 'qy'\n",
    "                elif tag in ('fe', 'ba'):                       tag = 'ba'\n",
    "                elif tag in ('oo', 'co', 'cc'):                 tag = 'oo_co_cc'\n",
    "                elif tag in ('fx', 'sv'):                       tag = 'sv'\n",
    "                elif tag in ('aap', 'am'):                      tag = 'aap_am'\n",
    "                elif tag in ('arp', 'nd'):                      tag = 'arp_nd'\n",
    "                elif tag in ('fo', 'o', 'fw', '\"', 'by', 'bc'): tag = 'fo_o_fw_\"_by_bc'            \n",
    "            d_tags.append(tag)\n",
    "        # Dan J says (p.c.) that it makes sense to take the first;\n",
    "        # there are only a handful of examples with 2 tags here.\n",
    "        return d_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "S8N_PUCAblq3",
    "outputId": "376b9a49-2ca8-452c-b52c-b83fea221184"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "reduced_df[\"act_tag\"] = reduced_df[\"act_tag\"].apply(lambda x: damsl_act_tag(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UNy0vvhhqpD"
   },
   "source": [
    "There are 43 tags in this dataset. Some of the tags are Yes-No-Question('qy'), Statement-non-opinion('sd') and Statement-opinion('sv'). Tags information can be found here http://compprag.christopherpotts.net/swda.html#tags. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9biiyP8UiGDe"
   },
   "source": [
    "To get unique tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrhW8gyLfQQK"
   },
   "outputs": [],
   "source": [
    "unique_tags = set()\n",
    "for tag in reduced_df['act_tag']:\n",
    "    unique_tags.add(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMOX5KwgiPmu"
   },
   "outputs": [],
   "source": [
    "one_hot_encoding_dic = pd.get_dummies(list(unique_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPHPCxE3iPby"
   },
   "outputs": [],
   "source": [
    "tags_encoding = []\n",
    "for i in range(0, len(reduced_df)):\n",
    "    tags_encoding.append(one_hot_encoding_dic[reduced_df['act_tag'].iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVI8QyVzjqWh"
   },
   "source": [
    "The tags are one hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQJTiffPjUtu"
   },
   "source": [
    "To create sentence embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmkyD1TfjWGO"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(0, len(reduced_df)):\n",
    "    sentences.append(reduced_df['text'].iloc[i].split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlD6L6e3jV-7"
   },
   "outputs": [],
   "source": [
    "wordvectors = {}\n",
    "index = 1\n",
    "for s in sentences:\n",
    "    for w in s:\n",
    "        if w not in wordvectors:\n",
    "            wordvectors[w] = index\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7_cjDHrjV1c"
   },
   "outputs": [],
   "source": [
    "# Max length of 137\n",
    "MAX_LENGTH = len(max(sentences, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LX6DidEvjVWs"
   },
   "outputs": [],
   "source": [
    "sentence_embeddings = []\n",
    "for s in sentences:\n",
    "    sentence_emb = []\n",
    "    for w in s:\n",
    "        sentence_emb.append(wordvectors[w])\n",
    "    sentence_embeddings.append(sentence_emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr4iEyNTjmlu"
   },
   "source": [
    "Then we split the dataset into test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiNZ-iI_jnOF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, np.array(tags_encoding))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_RqMeWe_jron"
   },
   "source": [
    "And pad the sentences with zero to make all sentences of equal length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqD7DvzRGRY7"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ai9cwv82jufe"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(X_test, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "Z-AO0mle-fLO"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "#Split Train into Train and Validation - about 10% into validation - In order to validate the model as it is training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQqOCdNLoAQn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "517zYSQLXkbn"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_input = train_sentences_X[:140000]\n",
    "val_input = train_sentences_X[140000:]\n",
    "\n",
    "train_labels = y_train[:140000]\n",
    "val_labels = y_train[140000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHJbZDtk7N-3"
   },
   "source": [
    "# Model 1 - \n",
    "\n",
    "The first approach we'll try is to treat DA tagging as a standard multi-class text classification task, in the way you've done before with sentiment analysis and other tasks. Each utterance will be treated independently as a text to be classified with its DA tag label. This model has an architecture of:\n",
    "\n",
    "- Embedding  \n",
    "- BLSTM  \n",
    "- Fully Connected Layer\n",
    "- Softmax Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FItlHC1Fjz6y"
   },
   "source": [
    " The model architecture is as follows: Embedding Layer (to generate word embeddings) Next layer Bidirectional LSTM. Feed forward layer with number of neurons = number of tags. Softmax activation to get the probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M97Sw5iv-lEU",
    "outputId": "f2dad82d-178d-41bf-968b-c36a19c941d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABSIZE: 43731, MAX_LENGTH: 137, EMBED_SIZE: 100, HIDDEN_SIZE:43\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(wordvectors) # 43,731\n",
    "MAX_LENGTH = len(max(sentences, key=len))\n",
    "EMBED_SIZE = 100 # arbitary\n",
    "HIDDEN_SIZE = len(unique_tags) \n",
    "print('VOCABSIZE: {}, MAX_LENGTH: {}, EMBED_SIZE: {}, HIDDEN_SIZE:{}'.format(VOCAB_SIZE, MAX_LENGTH, EMBED_SIZE, HIDDEN_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "colab_type": "code",
    "id": "LCaX-ptaj8G2",
    "outputId": "f4360619-d8b1-46aa-bdd9-ada7e5620a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 137, 100)          4373200   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 137, 86)           49536     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 86)                44720     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 43)                0         \n",
      "=================================================================\n",
      "Total params: 4,471,197\n",
      "Trainable params: 4,471,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.models import Sequential\n",
    "from tensorflow.compat.v1.keras.layers import LSTM\n",
    "from tensorflow.compat.v1.keras.layers import Dense\n",
    "from tensorflow.compat.v1.keras.layers import Dropout, InputLayer, Bidirectional, TimeDistributed, Activation, Embedding\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam\n",
    "\n",
    "#Building the network\n",
    "\n",
    "# Include 2 BLSTM layers, in order to capture both the forward and backward hidden states\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# Embedding layer\n",
    "model.add(Embedding(VOCAB_SIZE+1,100, input_length=MAX_LENGTH))\n",
    "# Bidirectional 1\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
    "# Bidirectional 2\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE)))\n",
    "# Dense layer\n",
    "model.add(Dense(HIDDEN_SIZE, activation='relu'))\n",
    "# Activation\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "colab_type": "code",
    "id": "OeiLkgD3Arpl",
    "outputId": "db2799db-2bbe-4526-d9fc-1dae96f0d016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 27704 samples\n",
      "Epoch 1/3\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.7107 - acc: 0.5713 - val_loss: 1.6181 - val_acc: 0.5972\n",
      "Epoch 2/3\n",
      "140000/140000 [==============================] - 140s 999us/sample - loss: 1.4895 - acc: 0.6307 - val_loss: 1.5262 - val_acc: 0.6138\n",
      "Epoch 3/3\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.4098 - acc: 0.6484 - val_loss: 1.4995 - val_acc: 0.6172\n"
     ]
    }
   ],
   "source": [
    "# Train the model - using validation \n",
    "history_model1= model.fit(x=train_input, y=train_labels, validation_data=(val_input,val_labels), epochs=3, verbose=1, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "2LkONUKQkSrL",
    "outputId": "0fcfdf5a-b033-4488-9f02-fe2ef68b1d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55902/55902 [==============================] - 109s 2ms/sample - loss: 1.5079 - acc: 0.6146\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_sentences_X, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Ab0ZL1dqkTY4",
    "outputId": "8e3a3e12-b044-433a-fd49-c885add3917e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 61.46112680435181\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy:\", score[1]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Agn772VQa6K6",
    "outputId": "185cfc0e-0e57-40a1-dd9b-a18763438741"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history_model1.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhMViQVSPY1J"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "\n",
    "The overall accuracy is 67%, an effective accuracy for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHwoVCEwjEz7"
   },
   "source": [
    "In addition to overall accuracy, you need to look at the accuracy of some minority classes. Signal-non-understanding ('br') is a good indicator of \"other-repair\" or cases in which the other conversational participant attempts to repair the speaker's error. Summarize/reformulate ('bf') has been used in dialogue summarization. Report the accuracy for these classes and some frequent errors you notice the system makes in predicting them. What do you think the reasons are？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7owA1f27se8"
   },
   "source": [
    "## Minority Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZ8BwgDxNcIr"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "predictions = model.predict(test_sentences_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5I26g20qQdzF",
    "outputId": "94ba6c71-4880-4bad-e8c4-47a8671ac751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3281    0    0 ...    0    0    0]\n",
      " [  17    0    0 ...    0    0    0]\n",
      " [  61    0    0 ...    0    0    0]\n",
      " ...\n",
      " [  11    0    0 ...    0    0    0]\n",
      " [  11    0    0 ...    0    0    0]\n",
      " [   8    0    0 ...    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.71      0.48      4652\n",
      "           1       0.00      0.00      0.00       205\n",
      "           2       0.00      0.00      0.00       170\n",
      "           3       0.00      0.00      0.00       294\n",
      "           4       0.94      0.96      0.95       921\n",
      "           5       0.00      0.00      0.00       178\n",
      "           6       0.00      0.00      0.00       497\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.00      0.00      0.00        22\n",
      "           9       0.58      0.66      0.62      1249\n",
      "          10       0.00      0.00      0.00       164\n",
      "          11       0.00      0.00      0.00        32\n",
      "          12       0.00      0.00      0.00      4018\n",
      "          13       0.70      0.97      0.81      9524\n",
      "          14       0.00      0.00      0.00        90\n",
      "          15       0.00      0.00      0.00      1209\n",
      "          16       0.68      0.85      0.76     18801\n",
      "          17       0.00      0.00      0.00        80\n",
      "          18       0.00      0.00      0.00        50\n",
      "          19       0.00      0.00      0.00       229\n",
      "          20       0.53      0.50      0.51      6558\n",
      "          21       0.00      0.00      0.00       151\n",
      "          22       0.00      0.00      0.00       300\n",
      "          23       0.00      0.00      0.00       693\n",
      "          24       0.00      0.00      0.00        83\n",
      "          25       0.00      0.00      0.00        26\n",
      "          26       0.00      0.00      0.00        31\n",
      "          27       0.00      0.00      0.00        20\n",
      "          28       0.00      0.00      0.00        50\n",
      "          29       0.00      0.00      0.00       357\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.00      0.00      0.00       137\n",
      "          32       0.00      0.00      0.00        26\n",
      "          33       0.00      0.00      0.00       259\n",
      "          34       0.00      0.00      0.00        64\n",
      "          35       0.00      0.00      0.00       255\n",
      "          36       0.47      0.32      0.38      2746\n",
      "          37       0.00      0.00      0.00       168\n",
      "          38       0.00      0.00      0.00       783\n",
      "          39       0.00      0.00      0.00       307\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00       367\n",
      "          42       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.61     55902\n",
      "   macro avg       0.10      0.12      0.10     55902\n",
      "weighted avg       0.49      0.61      0.54     55902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Build the confusion matrix off these predictions\n",
    "minority_balanced = sklearn.metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(minority_balanced)\n",
    "class_report = sklearn.metrics.classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "muWtF2t0W0zd",
    "outputId": "02314c2b-0bf8-434f-aef2-8f9d2277868f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize/reformulate Accuracy: 0.0\n",
      "Signal-non-understanding Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracies for \"br\" and \"bf\"\n",
    "bf_index = 19\n",
    "br_index = 29\n",
    "print('Summarize/reformulate Accuracy: {}'.format(minority_balanced[bf_index][bf_index]/sum(minority_balanced[bf_index])))\n",
    "print('Signal-non-understanding Accuracy: {}'.format((minority_balanced[br_index][br_index]/sum(minority_balanced[br_index]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdnpWLggZ-6z"
   },
   "source": [
    "\n",
    "Due to the reduced lack of training data for the minority classes, these minority classifiers will not be very confident in classification, as they have not been fully optimised. The frequent classifiers will be more optimised and will generate more confident scores for all examples, effectively crowding out the less confident minority classifiers. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZ16sE5F7x9e"
   },
   "source": [
    "# Model 2 - Balanced Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKHbOs4WkFaP"
   },
   "source": [
    "\n",
    "One thing we can do to try to improve performance is therefore to balance the data more sensibly. As the dataset is highly imbalanced, we can simply weight up the minority classes proportionally to their underrepresentation while training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6L4kNdf6kGEa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_integers = np.argmax(tags_encoding, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF1UM-ZMZoa1"
   },
   "source": [
    "## Define & Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "xIRgRAzOPSAZ",
    "outputId": "fb7a4fe1-d735-45bd-c4ea-04fd383709c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 137, 100)          4373200   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 137, 86)           49536     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 86)                44720     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 43)                0         \n",
      "=================================================================\n",
      "Total params: 4,471,197\n",
      "Trainable params: 4,471,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Re-built the model for the balanced training\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE+1,100, input_length=MAX_LENGTH))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE)))\n",
    "model.add(Dense(HIDDEN_SIZE, activation='relu'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "colab_type": "code",
    "id": "xB2McUREkL4B",
    "outputId": "87f31520-36d8-4250-f50d-0bc08b6bc740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 27704 samples\n",
      "Epoch 1/20\n",
      "140000/140000 [==============================] - 143s 1ms/sample - loss: 3.2296 - acc: 0.1179 - val_loss: 2.9466 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "140000/140000 [==============================] - 141s 1ms/sample - loss: 2.7678 - acc: 0.2764 - val_loss: 2.5037 - val_acc: 0.2931\n",
      "Epoch 3/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 2.4522 - acc: 0.3401 - val_loss: 2.5303 - val_acc: 0.3198\n",
      "Epoch 4/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 2.1761 - acc: 0.3870 - val_loss: 2.3202 - val_acc: 0.3327\n",
      "Epoch 5/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.9814 - acc: 0.4025 - val_loss: 2.1593 - val_acc: 0.3874\n",
      "Epoch 6/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.7835 - acc: 0.4329 - val_loss: 2.1350 - val_acc: 0.3636\n",
      "Epoch 7/20\n",
      "140000/140000 [==============================] - 140s 1000us/sample - loss: 1.6496 - acc: 0.4512 - val_loss: 1.9694 - val_acc: 0.4204\n",
      "Epoch 8/20\n",
      "140000/140000 [==============================] - 140s 997us/sample - loss: 1.5553 - acc: 0.4647 - val_loss: 2.0956 - val_acc: 0.3855\n",
      "Epoch 9/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.4485 - acc: 0.4802 - val_loss: 2.0333 - val_acc: 0.3586\n",
      "Epoch 10/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.3925 - acc: 0.4900 - val_loss: 2.0569 - val_acc: 0.3954\n",
      "Epoch 11/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.3524 - acc: 0.5036 - val_loss: 1.9960 - val_acc: 0.4105\n",
      "Epoch 12/20\n",
      "140000/140000 [==============================] - 141s 1ms/sample - loss: 1.3921 - acc: 0.4988 - val_loss: 2.0523 - val_acc: 0.3880\n",
      "Epoch 13/20\n",
      "140000/140000 [==============================] - 142s 1ms/sample - loss: 1.2721 - acc: 0.5305 - val_loss: 2.0732 - val_acc: 0.4001\n",
      "Epoch 14/20\n",
      "140000/140000 [==============================] - 141s 1ms/sample - loss: 1.2235 - acc: 0.5498 - val_loss: 2.0004 - val_acc: 0.4194\n",
      "Epoch 15/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.1864 - acc: 0.5587 - val_loss: 1.9672 - val_acc: 0.4246\n",
      "Epoch 16/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.1581 - acc: 0.5710 - val_loss: 1.9692 - val_acc: 0.4405\n",
      "Epoch 17/20\n",
      "140000/140000 [==============================] - 140s 1ms/sample - loss: 1.1647 - acc: 0.5678 - val_loss: 2.0418 - val_acc: 0.4114\n",
      "Epoch 18/20\n",
      "140000/140000 [==============================] - 141s 1ms/sample - loss: 1.1266 - acc: 0.5855 - val_loss: 1.9976 - val_acc: 0.4215\n",
      "Epoch 19/20\n",
      "140000/140000 [==============================] - 141s 1ms/sample - loss: 1.0997 - acc: 0.5942 - val_loss: 1.8788 - val_acc: 0.4509\n",
      "Epoch 20/20\n",
      "140000/140000 [==============================] - 142s 1ms/sample - loss: 1.1039 - acc: 0.5948 - val_loss: 1.8347 - val_acc: 0.4693\n"
     ]
    }
   ],
   "source": [
    "# Train the balanced network -  takes  time to achieve good accuracy\n",
    "history_model2 =model.fit(x=train_input, y=train_labels, validation_data=(val_input,val_labels), epochs=20, verbose=1, class_weight=d_class_weights, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "fs__uocKHzam",
    "outputId": "f420d756-fa5e-4591-f875-4d6c27f42a37"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history_model2.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJPjlMclZtw2"
   },
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "8UMAMGpJRINC",
    "outputId": "facbd13b-ed2a-4320-eda6-e75f5aab6b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55902/55902 [==============================] - 109s 2ms/sample - loss: 1.8296 - acc: 0.4725\n"
     ]
    }
   ],
   "source": [
    "# Overall Accuracy\n",
    "score = model.evaluate(test_sentences_X, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "0xzLIkTarjei",
    "outputId": "2b117d08-5b15-4252-c56e-5914d7aef440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 47.2469687461853\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkULcz2igEW3"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "label_pred = model.predict(test_sentences_X, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hq7i7giWZ4_l"
   },
   "source": [
    "## Balanced network evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fM7VWweco0Et"
   },
   "source": [
    "Report the overall accuracy and the accuracy of  'br' and 'bf'  classes. Suggest other ways to handle imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "colab_type": "code",
    "id": "4jNfWmSNgRvT",
    "outputId": "d0a1b81b-22df-451e-89dd-6b56815d9388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.46      0.51      4652\n",
      "           1       0.04      0.27      0.07       205\n",
      "           2       0.08      0.14      0.10       170\n",
      "           3       0.24      0.68      0.36       294\n",
      "           4       0.00      0.00      0.00       921\n",
      "           5       0.10      0.36      0.16       178\n",
      "           6       0.60      0.62      0.61       497\n",
      "           7       0.37      0.67      0.48        61\n",
      "           8       0.04      0.32      0.06        22\n",
      "           9       0.57      0.64      0.60      1249\n",
      "          10       0.55      0.54      0.54       164\n",
      "          11       0.00      0.00      0.00        32\n",
      "          12       0.77      0.71      0.74      4018\n",
      "          13       0.91      0.64      0.75      9524\n",
      "          14       0.10      0.36      0.15        90\n",
      "          15       0.64      0.43      0.51      1209\n",
      "          16       0.77      0.42      0.55     18801\n",
      "          17       0.03      0.30      0.06        80\n",
      "          18       0.32      0.70      0.44        50\n",
      "          19       0.02      0.17      0.04       229\n",
      "          20       0.34      0.39      0.37      6558\n",
      "          21       0.06      0.26      0.09       151\n",
      "          22       0.12      0.51      0.20       300\n",
      "          23       0.28      0.47      0.35       693\n",
      "          24       0.58      0.47      0.52        83\n",
      "          25       0.06      0.31      0.10        26\n",
      "          26       0.00      0.00      0.00        31\n",
      "          27       0.19      0.80      0.31        20\n",
      "          28       0.01      0.08      0.01        50\n",
      "          29       0.50      0.73      0.60       357\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.11      0.47      0.18       137\n",
      "          32       0.01      0.04      0.01        26\n",
      "          33       0.03      0.08      0.05       259\n",
      "          34       0.01      0.12      0.02        64\n",
      "          35       0.52      0.85      0.65       255\n",
      "          36       0.59      0.19      0.28      2746\n",
      "          37       0.02      0.05      0.03       168\n",
      "          38       0.14      0.69      0.23       783\n",
      "          39       0.07      0.21      0.11       307\n",
      "          40       0.05      0.68      0.10        25\n",
      "          41       0.28      0.66      0.39       367\n",
      "          42       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.47     55902\n",
      "   macro avg       0.25      0.38      0.26     55902\n",
      "weighted avg       0.64      0.47      0.52     55902\n",
      "\n",
      "Summarize/reformulate Accuracy: 0.17467248908296942\n",
      "Signal-non-understanding Accuracy: 0.7338935574229691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Build the confusion matrix off these predictions\n",
    "\n",
    "matrix_balanced = sklearn.metrics.confusion_matrix(y_test.argmax(axis=1), label_pred.argmax(axis=1))\n",
    "\n",
    "balanced_class_report = sklearn.metrics.classification_report(y_test.argmax(axis=1), label_pred.argmax(axis=1))\n",
    "print(balanced_class_report)\n",
    "# Calculate Accuracies for \"br\" and \"bf\"\n",
    "print('Summarize/reformulate Accuracy: {}'.format(matrix_balanced[bf_index][bf_index]/sum(matrix_balanced[bf_index])))\n",
    "print('Signal-non-understanding Accuracy: {}'.format((matrix_balanced[br_index][br_index]/sum(matrix_balanced[br_index]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zi9GyVUvPcrF"
   },
   "source": [
    "\n",
    "\n",
    "### Accuracies\n",
    "\n",
    "\n",
    "\n",
    "### Explanation\n",
    "\n",
    "\n",
    "### Other ways to handle imbalanced classes\n",
    "\n",
    "\n",
    "- Remove samples from the majority classes to balance out the inbalanced dataset.\n",
    "\n",
    "- Utilise a generative model to produce samples of the minority classes using those classes' probability disitributions to balance out the imbalanced dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fW4g5mQkkaFv"
   },
   "source": [
    "Can we improve things by using context information?  Next we try to build a model which predicts DA tag from the sequence of \n",
    "previous DA tags, plus the utterance representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfrGWuZ6nk4y"
   },
   "source": [
    "# Using Context for Dialog Act Classification\n",
    "\n",
    "The second approach we will try is a hierarchical approach to DA tagging. We expect there is valuable sequential information among the DA tags. So in this section we apply a BiLSTM on top of the sentence CNN representation. The CNN model learns textual information in each utterance for DA classification, acting like the text classifier from Model 1 above. Then we use a bidirectional-LSTM (BLSTM) above that to learn how to use the context before and after the current utterance to improve the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qyPpNaK-2mb"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "This model has an architecture of:\n",
    "\n",
    "- Word Embedding\n",
    "- CNN\n",
    "- Bidirectional LSTM\n",
    "- Fully-Connected output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuJLqgjWqcIf"
   },
   "source": [
    "## CNN\n",
    "\n",
    "\n",
    "This is a classical CNN layer used to convolve over embedings tensor and gether useful information from it. The data is represented by hierarchy of features, which can be modelled using a CNN. We transform/reshape conv output to 2d matrix. Then we pass it to the max pooling layer that applies the max pool operation on windows of different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "XA5INtFl-fM0",
    "outputId": "da6e6a76-3ece-40f7-ff99-60b4ecaed59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras.layers import Input, Embedding, Reshape, Conv2D, BatchNormalization, MaxPool2D, Concatenate, Flatten, Dense, Dropout, TimeDistributed\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 64\n",
    "drop = 0.2\n",
    "VOCAB_SIZE = len(wordvectors) # 43,731\n",
    "MAX_LENGTH = len(max(sentences, key=len))\n",
    "EMBED_SIZE = 100 # arbitary\n",
    "HIDDEN_SIZE = len(unique_tags) \n",
    "\n",
    "# CNN model\n",
    "inputs = Input(shape=(MAX_LENGTH, ), dtype='int32')\n",
    "embedding = Embedding(input_dim=VOCAB_SIZE+1, output_dim=EMBED_SIZE, input_length=MAX_LENGTH)(inputs)\n",
    "reshape = Reshape((MAX_LENGTH, EMBED_SIZE, 1))(embedding)\n",
    "\n",
    "# 3 convolutions\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBED_SIZE), strides=1, padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "bn_0 = BatchNormalization()(conv_0)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBED_SIZE), strides=1, padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "bn_1 = BatchNormalization()(conv_1)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBED_SIZE), strides=1, padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "bn_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "# maxpool for 3 layers\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[0] + 1, 1), padding='valid')(bn_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[1] + 1, 1), padding='valid')(bn_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[2] + 1, 1), padding='valid')(bn_2)\n",
    "\n",
    "# concatenate tensors\n",
    "conc = Concatenate()([maxpool_0, maxpool_1, maxpool_2])\n",
    "# flatten concatenated tensors\n",
    "flat = TimeDistributed(Flatten())(conc)\n",
    "# dense layer (dense_1)\n",
    "s = np.shape(flat)\n",
    "dense_1 = Dense(100, activation='relu')(flat)\n",
    "# dropout_1\n",
    "dropout_1 = Dropout(drop)(dense_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDuERMw7-rAV"
   },
   "source": [
    "## BLSTM\n",
    "\n",
    "This is used to create LSTM layers. The data we’re working with has temporal properties which we want to model as well — hence the use of a LSTM. You should create a BiLSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFGp2EWI-fM7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import Bidirectional, LSTM\n",
    "# BLSTM model\n",
    "ds = np.shape(dropout_1)\n",
    "\n",
    "# Bidirectional 1u\n",
    "bi_1 = Bidirectional(LSTM(100, return_sequences=True))(dropout_1)\n",
    "\n",
    "# Bidirectional 2\n",
    "b1s = np.shape(bi_1)\n",
    "bi_2 = Bidirectional(LSTM(100))(bi_1)\n",
    "\n",
    "# Dense layer (dense_2)\n",
    "b2s = np.shape(bi_2)\n",
    "dense_2 = Dense(100, activation='relu')(bi_2)\n",
    "\n",
    "# dropout_2\n",
    "dropout_2 = Dropout(drop)(dense_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wluAkx6AQUb"
   },
   "source": [
    "Concatenate 2 last layers and create the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kzrhgkX2-fNE",
    "outputId": "aa6d7a0a-e8b7-4fd0-a4b0-319fa8391261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 137)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 137, 100)     4373200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 137, 100, 1)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 135, 1, 64)   19264       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 134, 1, 64)   25664       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 133, 1, 64)   32064       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 135, 1, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 134, 1, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 133, 1, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 1, 1, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 1, 192)    0           max_pooling2d[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 1, 192)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 100)       19300       time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 100)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 200)       160800      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 200)          240800      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          20100       bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           flatten_1[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 43)           8643        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,900,603\n",
      "Trainable params: 4,900,219\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# concatenate 2 final layers\n",
    "dropout_1_flat = Flatten()(dropout_1)\n",
    "final_conc = Concatenate()([dropout_1_flat,dropout_2])\n",
    "# output\n",
    "output = Dense(43, activation='softmax')(final_conc)\n",
    "\n",
    "cnn_model = Model(inputs=[inputs], outputs=[output])\n",
    "cnn_model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "3Jneg-GD-fNJ",
    "outputId": "e3a30eee-b4a3-4895-8065-36b07a32462a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 27704 samples\n",
      "Epoch 1/4\n",
      "140000/140000 [==============================] - 9s 67us/sample - loss: 0.4912 - acc: 0.8454 - val_loss: 1.0355 - val_acc: 0.7015\n",
      "Epoch 2/4\n",
      "140000/140000 [==============================] - 9s 67us/sample - loss: 0.4389 - acc: 0.8596 - val_loss: 1.1532 - val_acc: 0.6917\n",
      "Epoch 3/4\n",
      "140000/140000 [==============================] - 9s 68us/sample - loss: 0.4017 - acc: 0.8693 - val_loss: 1.2731 - val_acc: 0.6952\n",
      "Epoch 4/4\n",
      "140000/140000 [==============================] - 9s 67us/sample - loss: 0.3810 - acc: 0.8754 - val_loss: 1.3132 - val_acc: 0.6913\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model - using validation \n",
    "cnn_history = cnn_model.fit(x=train_input, y=train_labels, validation_data=(val_input,val_labels), epochs=4, verbose=1, batch_size=1000)\n",
    "\n",
    "\n",
    "acc = cnn_history.history['acc']\n",
    "val_acc = cnn_history.history['val_acc']\n",
    "loss = cnn_history.history['loss']\n",
    "val_loss = cnn_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSMRSX1u-fNO",
    "outputId": "27120468-ed62-4b59-c2ba-301a5a5582eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55902/55902 [==============================] - 3s 53us/sample - loss: 1.3202 - acc: 0.6920\n"
     ]
    }
   ],
   "source": [
    "score = cnn_model.evaluate(test_sentences_X, y_test, batch_size=100)\n",
    "label_pred = model.predict(test_sentences_X, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3qFMsXNS-fNS",
    "outputId": "55730e4b-c9f5-403c-c000-bf8b67acb8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 69.20324563980103\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "colab_type": "code",
    "id": "wfPTAdCuC1NF",
    "outputId": "29761df2-dfbe-40ff-f20c-2aa55b3f8055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.08      0.01       261\n",
      "           1       0.00      0.00      0.00       775\n",
      "           2       0.00      0.00      0.00        73\n",
      "           3       0.00      0.00      0.00       220\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00       188\n",
      "           6       0.00      0.00      0.00       917\n",
      "           7       0.00      0.00      0.00       189\n",
      "           8       0.00      0.00      0.00       239\n",
      "           9       0.00      0.00      0.00     18909\n",
      "          10       0.00      0.00      0.00       169\n",
      "          11       0.00      0.01      0.00      1216\n",
      "          12       0.00      0.00      0.00       147\n",
      "          13       0.00      0.00      0.00        78\n",
      "          14       0.01      0.57      0.01       296\n",
      "          15       0.00      0.00      0.00        19\n",
      "          16       0.00      0.00      0.00        49\n",
      "          17       0.00      0.00      0.00        23\n",
      "          18       0.00      0.00      0.00      1169\n",
      "          19       0.00      0.00      0.00       265\n",
      "          20       0.01      0.00      0.00      2824\n",
      "          21       0.00      0.00      0.00        33\n",
      "          22       0.00      0.00      0.00      3924\n",
      "          23       0.00      0.00      0.00        25\n",
      "          24       0.00      0.00      0.00       327\n",
      "          25       0.00      0.10      0.00        31\n",
      "          26       0.00      0.00      0.00        51\n",
      "          27       0.00      0.00      0.00      4723\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00        67\n",
      "          30       0.00      0.00      0.00       137\n",
      "          31       0.00      0.00      0.00       626\n",
      "          32       0.00      0.00      0.00       462\n",
      "          33       0.00      0.00      0.00        60\n",
      "          34       0.00      0.00      0.00        76\n",
      "          35       0.00      0.00      0.00        25\n",
      "          36       0.00      0.00      0.00        18\n",
      "          37       0.00      0.00      0.00      9508\n",
      "          38       0.00      0.00      0.00       152\n",
      "          39       0.00      0.00      0.00       338\n",
      "          40       0.00      0.00      0.00       293\n",
      "          41       0.00      0.00      0.00       217\n",
      "          42       0.00      0.00      0.00      6736\n",
      "\n",
      "    accuracy                           0.00     55902\n",
      "   macro avg       0.00      0.02      0.00     55902\n",
      "weighted avg       0.00      0.00      0.00     55902\n",
      "\n",
      "Summarize/reformulate Accuracy: 0.0\n",
      "Signal-non-understanding Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cnn_matrix = sklearn.metrics.confusion_matrix(y_test.argmax(axis=1), label_pred.argmax(axis=1))\n",
    "bf_index = 19\n",
    "br_index = 29\n",
    "cnn_class_report = sklearn.metrics.classification_report(y_test.argmax(axis=1), label_pred.argmax(axis=1))\n",
    "print(cnn_class_report)\n",
    "# Calculate Accuracies for \"br\" and \"bf\"\n",
    "print('Summarize/reformulate Accuracy: {}'.format(cnn_matrix[bf_index][bf_index]/sum(cnn_matrix[bf_index])))\n",
    "print('Signal-non-understanding Accuracy: {}'.format((cnn_matrix[br_index][br_index]/sum(cnn_matrix[br_index]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RKMmrfuisKGJ"
   },
   "source": [
    "**Report** your overall accuracy. Did context help disambiguate and better predict the minority classes ('br' and 'bf')? What are frequent errors? Show one positive example where adding context changed the prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmO6hVsWTaNr"
   },
   "source": [
    "### Minority Classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUZt48JgrE34"
   },
   "source": [
    "# Advanced:  Bert-Based Model for Dialogue Act Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE63Q5guuPdA"
   },
   "source": [
    "In the last section we want to use BERT and leverage contextual word embeddings, following on from the last lab you've \n",
    "just done. This is an advanced part of the assignment and worth 10 marks (20%) in total. You could use your BERT-based text classifier here (instead of the CNN utterance-level classifier) and see if a pre-trained BERT language model helps. The domain difference from conversational data is one possible downside to using BERT. Explore some techniques to efficiently transfer the knowledge from conversational data and to improve model performance on DA tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_fiV-Wlk4yd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "import sklearn\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "max_seq_length = 256\n",
    "labels = reduced_df['act_tag']\n",
    "train_text, test_text, train_label, test_label = train_test_split(np.array(sentences), labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "0a238332e38d4ea58f814d874dc2a156",
      "f5bfeac91df5420d9ceb757bd4e13811",
      "2369e3336b0a49769f175a189ac14d23",
      "f3528762220042a8b210058707cb10a6",
      "02510cbe5f7f4d11b678db72f72c4cb4",
      "dec787a2f91f4b7383dc5f6f8077d3ca",
      "fc6acda69ce64e339ee3095ef8ad0268",
      "1f76b789fcc849d6b1d75b5e59e95f9e",
      "ff7960e11aaf40b088f7a5c2649aae93",
      "4aee85c0f744445e89467d44340d60c3",
      "84d435a0b8e84169a3618692a2420788",
      "bb640f5b752e4014a6ea15473b6c7227",
      "c40dc0d6186f469aa27037f6c2116c06",
      "63a78c695ca14ee3a68f5a6a21b32a2a",
      "8d9249a15bfd4f03bbac5a24dbd93acd",
      "56adfb368704444688e9625814443fc4"
     ]
    },
    "colab_type": "code",
    "id": "KUD7JW8yqGPV",
    "outputId": "b1036c57-0d34-4fa6-9e27-1d6ebd8a7ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a238332e38d4ea58f814d874dc2a156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=167704, style=ProgressS…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7960e11aaf40b088f7a5c2649aae93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=55902, style=ProgressSt…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "class InputExample(object):\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "\n",
    "    bert_module =  hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples\n",
    "\n",
    "# Task 1\n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "# Convert data to InputExample format\n",
    "InputExamplesTrain=convert_text_to_examples(train_text,train_label)\n",
    "InputExamplesTest=convert_text_to_examples(test_text,test_label)\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels) = convert_examples_to_features(tokenizer, InputExamplesTrain)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels) = convert_examples_to_features(tokenizer, InputExamplesTest)\n",
    "\n",
    "train_labels = sklearn.preprocessing.OneHotEncoder().fit_transform(train_labels)\n",
    "test_labels = sklearn.preprocessing.OneHotEncoder().fit_transform(test_labels)\n",
    "# End of Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_9CINCAqHvz"
   },
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "wk5xt4lqqMkN",
    "outputId": "6e481b25-690c-431f-d191-984c5719732e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "# Build model\n",
    "\n",
    "input_ids = tf.keras.layers.Input((max_seq_length,), dtype='float32', name='IDInput')\n",
    "input_masks = tf.keras.layers.Input((max_seq_length,), dtype='float32', name='MASKSInput')\n",
    "input_segment_ids = tf.keras.layers.Input((max_seq_length,), dtype='float32', name='SEGMENTIDInput')\n",
    "major_input = [input_ids, input_masks, input_segment_ids]\n",
    "bert = BertLayer(n_fine_tune_layers=1)(major_input)\n",
    "output = tf.keras.layers.Dense(43, activation='softmax')(bert)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[major_input], outputs = [output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# End of Task 2\n",
    "\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OhATJRQRqVkN",
    "outputId": "1f5b796d-62fd-47f7-c7c3-ace1fc90c43c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 167704 samples, validate on 55902 samples\n",
      "167704/167704 [==============================] - 8556s 51ms/sample - loss: 0.9997 - acc: 0.6988 - val_loss: 0.8836 - val_acc: 0.7261\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "#print(type(train_input_ids), type(train_input_masks), type(train_segment_ids), type(train_labels))\n",
    "#print(np.shape(train_input_ids), np.shape(train_input_masks), np.shape(train_segment_ids), np.shape(train_labels))\n",
    "\n",
    "bert_model_hist = model.fit([train_input_ids, train_input_masks, train_segment_ids], train_labels,validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels), epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Zlfji56_uthw",
    "outputId": "b9f2dae6-389f-40e4-a84d-ca38d6d62b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55902/55902 [==============================] - 1940s 35ms/sample - loss: 0.8836 - acc: 0.7261\n",
      "Overall Accuracy: 72.60921001434326\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate([test_input_ids, test_input_masks, test_segment_ids], test_labels, batch_size=32)\n",
    "label_pred = model.predict([test_input_ids, test_input_masks, test_segment_ids], batch_size=32)\n",
    "print(\"Overall Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YHzVEeb6EMM2",
    "outputId": "19f1443f-5815-4e67-dc00-7dbb70861836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2312175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78      3922\n",
      "           1       0.75      0.71      0.73      4592\n",
      "           2       0.00      0.00      0.00       181\n",
      "           3       0.36      0.33      0.35        27\n",
      "           4       0.86      0.36      0.50       152\n",
      "           5       0.00      0.00      0.00       252\n",
      "           6       0.62      0.26      0.36      2755\n",
      "           7       0.00      0.00      0.00        23\n",
      "           8       0.63      0.13      0.22       180\n",
      "           9       0.00      0.00      0.00        94\n",
      "          10       0.00      0.00      0.00        53\n",
      "          11       0.75      0.94      0.84      9435\n",
      "          12       0.12      0.14      0.13       175\n",
      "          13       0.78      0.61      0.69      1211\n",
      "          14       0.00      0.00      0.00        21\n",
      "          15       0.00      0.00      0.00       248\n",
      "          16       0.80      0.70      0.74       250\n",
      "          17       0.38      0.57      0.45       320\n",
      "          18       0.42      0.52      0.47        92\n",
      "          19       0.55      0.30      0.39        20\n",
      "          20       0.83      0.51      0.63       682\n",
      "          21       0.27      0.20      0.23       291\n",
      "          22       0.62      0.66      0.64        61\n",
      "          23       0.35      0.52      0.42        25\n",
      "          24       0.75      0.69      0.72       288\n",
      "          25       0.00      0.00      0.00       197\n",
      "          26       0.00      0.00      0.00        79\n",
      "          27       0.56      0.72      0.63       355\n",
      "          28       0.00      0.00      0.00        65\n",
      "          29       0.31      0.08      0.12       783\n",
      "          30       0.17      0.03      0.05        38\n",
      "          31       0.50      0.02      0.04       138\n",
      "          32       0.91      0.31      0.46       170\n",
      "          33       0.00      0.00      0.00        51\n",
      "          34       0.62      0.80      0.70       493\n",
      "          35       0.00      0.00      0.00        17\n",
      "          36       0.70      0.85      0.77      1214\n",
      "          37       0.43      0.01      0.02       277\n",
      "          38       0.75      0.88      0.81     18930\n",
      "          39       0.59      0.53      0.56      6760\n",
      "          40       0.00      0.00      0.00        29\n",
      "          41       0.00      0.00      0.00        29\n",
      "          42       0.97      0.98      0.98       927\n",
      "\n",
      "    accuracy                           0.73     55902\n",
      "   macro avg       0.40      0.33      0.34     55902\n",
      "weighted avg       0.70      0.73      0.70     55902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-ef31f69fe57c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_class_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate Accuracies for \"br\" and \"bf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Summarize/reformulate Accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbf_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbf_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbf_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Signal-non-understanding Accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbr_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbr_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbr_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(label_pred.argmax())\n",
    "#bert_matrix = sklearn.metrics.confusion_matrix(test_label.argmax(), label_pred.argmax(axis=1))\n",
    "bf_index = 19 #rerun cell\n",
    "br_index = 29\n",
    "bert_class_report = sklearn.metrics.classification_report(test_labels.argmax(axis=1), label_pred.argmax(axis=1))\n",
    "print(bert_class_report)\n",
    "# Calculate Accuracies for \"br\" and \"bf\"\n",
    "#print('Summarize/reformulate Accuracy: {}'.format(bert_matrix[bf_index][bf_index]/sum(bert_matrix[bf_index])))\n",
    "#print('Signal-non-understanding Accuracy: {}'.format((bert_matrix[br_index][br_index]/sum(bert_matrix[br_index]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yu9i9-mcEazL",
    "outputId": "c14c3e05-68d1-4089-c504-c68052d12590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<Throat_clearing>', '[', 'I', 'guess,', '+', 'I', 'guess', '', ']', 'by', 'what', 'you', 'said', '', '[', \"you're,\", '+', '', 'you', '', \"don't\", ']', 'feel', 'your,', '', '', '{F', 'uh,', '}', 'privacy', 'has', 'been', '[', 'inva-,', '+', 'invaded', ']', 'anytime', 'recently?', '/']\n",
      "Label:\n",
      "  (0, 39)\t1.0\n",
      "Prdicted:\n",
      "38\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['No,', '', '/']\n",
      "Label:\n",
      "  (0, 38)\t1.0\n",
      "Prdicted:\n",
      "38\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['not', 'really.', '', '/']\n",
      "Label:\n",
      "  (0, 38)\t1.0\n",
      "Prdicted:\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['{F', 'Uh,', '}', '[', '[', '', '{F', 'u-,', '}', 'th-,', '', '+', '{F', 'uh,', '}', 'th-,', ']', '+', 'the', ']', 'only', 'thing', 'that', 'annoys', 'me', 'is', 'when,', '{F', 'uh,', '}', 'people', 'call', 'and', '[', 'they,', '+', '{F', 'uh,', '}', 'you', ']', 'have', 'solicitation', 'calls.', '/']\n",
      "Label:\n",
      "  (0, 28)\t1.0\n",
      "Prdicted:\n",
      "38\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['Uh-huh.', '/']\n",
      "Label:\n",
      "  (0, 34)\t1.0\n",
      "Prdicted:\n",
      "34\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "[\"That's\", 'the', 'only', 'thing', 'that', 'bothers', 'me.', '', '', '/']\n",
      "Label:\n",
      "  (0, 38)\t1.0\n",
      "Prdicted:\n",
      "38\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "[\"That's\", 'not', 'really', 'invading', 'my', 'privacy', '<laughter>.', '/']\n",
      "Label:\n",
      "  (0, 29)\t1.0\n",
      "Prdicted:\n",
      "11\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['Right.', '/']\n",
      "Label:\n",
      "  (0, 11)\t1.0\n",
      "Prdicted:\n",
      "11\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['{F', 'Uh,', '}', '<<pause>>', 'do', 'you', 'feel', 'that', 'yours', 'is', 'invaded?', '/']\n",
      "Label:\n",
      "  (0, 11)\t1.0\n",
      "Prdicted:\n",
      "11\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['{F', 'Uh,', '}', 'no', '', '/']\n",
      "Label:\n",
      "  (0, 39)\t1.0\n",
      "Prdicted:\n",
      "39\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['I', \"wouldn't\", 'call', 'it', 'invading', 'my', 'privacy', 'by', 'any', 'means.', '', '/']\n",
      "Label:\n",
      "  (0, 6)\t1.0\n",
      "Prdicted:\n",
      "29\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['{F', 'Uh,', '}', '{D', 'you', 'know,', '}', 'I', 'would,', '-', '/']\n",
      "Label:\n",
      "  (0, 11)\t1.0\n",
      "Prdicted:\n",
      "11\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['[', 'there,', '+', \"there's\", '', ']', 'a', 'lot', 'of', 'times', 'though,', '{F', 'uh,', '}', 'you', 'get', 'those', 'calls', '[', 'and,', '+', ']', '', '{D', 'you', 'know,', '}', 'when', \"you're\", 'sitting', 'at', 'home', 'wanting', 'to', 'relax', '[', 'or,', '+', 'or', ']', 'whatnot', '', '/']\n",
      "Label:\n",
      "  (0, 1)\t1.0\n",
      "Prdicted:\n",
      "1\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['{C', 'and,', '}', '{D', 'you', 'know,', '}', 'next', 'thing', 'you', 'know,', '{F', 'uh,', '}', 'someone', 'calls', 'and', 'wants', 'to', 'sell', 'you', 'this', 'or', '', 'that', '', '/']\n",
      "Label:\n",
      "  (0, 11)\t1.0\n",
      "Prdicted:\n",
      "11\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "['{C', 'and', '}', \"it's\", 'real', 'hard', '[', 'to,', '+', 'to', '', ']', 'tell', 'them,', '{D', 'you', 'know,', '}', 'that', \"you're\", 'not', 'interested.', '', '/']\n",
      "Label:\n",
      "  (0, 38)\t1.0\n",
      "Prdicted:\n",
      "39\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "  print(sentences[i])\n",
    "  print('Label:')\n",
    "  print(test_labels[i])\n",
    "  print('Prdicted:')\n",
    "  print(np.array(label_pred[i]).argmax())\n",
    "  print('--------------------------------------------------')\n",
    "  print('--------------------------------------------------')\n",
    "  print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWOHRDGSpcfL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Lab 11 Dialogue Act Tagging.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02510cbe5f7f4d11b678db72f72c4cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0a238332e38d4ea58f814d874dc2a156": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2369e3336b0a49769f175a189ac14d23",
       "IPY_MODEL_f3528762220042a8b210058707cb10a6"
      ],
      "layout": "IPY_MODEL_f5bfeac91df5420d9ceb757bd4e13811"
     }
    },
    "1f76b789fcc849d6b1d75b5e59e95f9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2369e3336b0a49769f175a189ac14d23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Converting examples to features: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dec787a2f91f4b7383dc5f6f8077d3ca",
      "max": 167704,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02510cbe5f7f4d11b678db72f72c4cb4",
      "value": 167704
     }
    },
    "4aee85c0f744445e89467d44340d60c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56adfb368704444688e9625814443fc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63a78c695ca14ee3a68f5a6a21b32a2a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84d435a0b8e84169a3618692a2420788": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Converting examples to features: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63a78c695ca14ee3a68f5a6a21b32a2a",
      "max": 55902,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c40dc0d6186f469aa27037f6c2116c06",
      "value": 55902
     }
    },
    "8d9249a15bfd4f03bbac5a24dbd93acd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb640f5b752e4014a6ea15473b6c7227": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56adfb368704444688e9625814443fc4",
      "placeholder": "​",
      "style": "IPY_MODEL_8d9249a15bfd4f03bbac5a24dbd93acd",
      "value": " 55902/55902 [00:12&lt;00:00, 4357.26it/s]"
     }
    },
    "c40dc0d6186f469aa27037f6c2116c06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dec787a2f91f4b7383dc5f6f8077d3ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3528762220042a8b210058707cb10a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f76b789fcc849d6b1d75b5e59e95f9e",
      "placeholder": "​",
      "style": "IPY_MODEL_fc6acda69ce64e339ee3095ef8ad0268",
      "value": " 167704/167704 [00:39&lt;00:00, 4259.90it/s]"
     }
    },
    "f5bfeac91df5420d9ceb757bd4e13811": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc6acda69ce64e339ee3095ef8ad0268": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff7960e11aaf40b088f7a5c2649aae93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84d435a0b8e84169a3618692a2420788",
       "IPY_MODEL_bb640f5b752e4014a6ea15473b6c7227"
      ],
      "layout": "IPY_MODEL_4aee85c0f744445e89467d44340d60c3"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
